{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rEKiUIZ_J8l",
        "outputId": "d3b8533a-0bdc-433a-d76c-0a4c3cd49074"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=e965dcbf60dd930be92fd38e9551ec16afc18e9442c3ffb36b507b69219829ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import holidays\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml import Transformer\n",
        "from pyspark.sql.functions import lit, udf\n",
        "from pyspark.ml.param.shared import HasInputCols, HasOutputCol\n",
        "from datetime import date"
      ],
      "metadata": {
        "id": "UDasMQpA_C2y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9U444xfe-wZa"
      },
      "outputs": [],
      "source": [
        "# Create a SparkSession\n",
        "#spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n",
        "\n",
        "data = [('2022-02-01',1, 1, 13),('2023-01-02', 1, 1, 11), ('2024-04-23', 1, 1, 14), ('2023-03-04', 1, 1, 10), ('2021-05-05', 1, 1, 10) ]\n",
        "cols = ['date', 'company', 'product', 'barcode']\n",
        "\n",
        "df = spark.createDataFrame(data, cols).withColumn('date', F.to_date('date', 'yyy-MM-dd'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luk9obKr_bm6",
        "outputId": "a2cb9e56-3eda-47fc-f15b-7b8e456969e0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+-------+-------+\n",
            "|      date|company|product|barcode|\n",
            "+----------+-------+-------+-------+\n",
            "|2022-02-01|      1|      1|     13|\n",
            "|2023-01-02|      1|      1|     11|\n",
            "|2024-04-23|      1|      1|     14|\n",
            "|2023-03-04|      1|      1|     10|\n",
            "|2021-05-05|      1|      1|     10|\n",
            "+----------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AddDateFeaturesTransformer(Transformer, HasInputCols, HasOutputCol):\n",
        "    def __init__(self, inputCol=None, outputCols=None, country_code=None):\n",
        "        super(AddDateFeaturesTransformer, self).__init__()\n",
        "        self.inputCol = inputCol\n",
        "        self.outputCols = outputCols\n",
        "        self.country_code = country_code\n",
        "\n",
        "    def is_holiday(self, date_str: date, country_code: str='TR'):\n",
        "        date_str = str(date_str)\n",
        "        country_holidays = holidays.CountryHoliday(country_code)\n",
        "        date_obj = date.fromisoformat(date_str)\n",
        "        if date_obj in country_holidays:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def _transform(self, df):\n",
        "        is_holiday = udf(self.is_holiday, IntegerType())\n",
        "\n",
        "        df = df.withColumn(self.outputCols[0], F.year(self.inputCol)) \\\n",
        "        .withColumn(self.outputCols[1], F.month(self.inputCol)) \\\n",
        "        .withColumn(self.outputCols[2], F.dayofweek(self.inputCol)) \\\n",
        "        .withColumn(self.outputCols[3], is_holiday(self.inputCol))\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "58HdqgkDMiYl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AddDateFeaturesTransformer(inputCol='date', outputCols=['year', 'month', 'dayofweek', 'is_holiday'],\n",
        "                           country_code='TR').transform(df).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiUbO-chMiW0",
        "outputId": "46950d79-30f8-48bf-df9d-e4c93f9c0896"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+-------+-------+----+-----+---------+----------+\n",
            "|      date|company|product|barcode|year|month|dayofweek|is_holiday|\n",
            "+----------+-------+-------+-------+----+-----+---------+----------+\n",
            "|2022-02-01|      1|      1|     13|2022|    2|        3|         0|\n",
            "|2023-01-02|      1|      1|     11|2023|    1|        2|         0|\n",
            "|2024-04-23|      1|      1|     14|2024|    4|        3|         1|\n",
            "|2023-03-04|      1|      1|     10|2023|    3|        7|         0|\n",
            "|2021-05-05|      1|      1|     10|2021|    5|        4|         0|\n",
            "+----------+-------+-------+-------+----+-----+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kb__uaTEMh9e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}